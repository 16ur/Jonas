#!/usr/bin/env python3
"""
Script de processing des donn√©es IAS (Indicateur Activit√© Syndromique)
Traite les donn√©es nationales et r√©gionales pour cr√©er un fichier unifi√©
"""

import pandas as pd
import numpy as np
from pathlib import Path

print("\n" + "="*70)
print("  PROCESSING IAS - DONN√âES NATIONALES ET R√âGIONALES")
print("="*70 + "\n")

BASE_DIR = Path(__file__).resolve().parent.parent
RAW_DIR = BASE_DIR / 'data' / 'raw'
PROCESSED_DIR = BASE_DIR / 'data' / 'processed'

# ============================================================================
# MAPPING ANCIENNES R√âGIONS ‚Üí NOUVELLES R√âGIONS
# ============================================================================

# Codes r√©gions dans Openhealth (anciennes r√©gions, codes INSEE)
REGION_CODE_TO_NAME = {
    '11': '√éle-de-France',
    '21': 'Champagne-Ardenne',
    '22': 'Picardie',
    '23': 'Haute-Normandie',
    '24': 'Centre',
    '25': 'Basse-Normandie',
    '26': 'Bourgogne',
    '31': 'Nord-Pas-de-Calais',
    '41': 'Lorraine',
    '42': 'Alsace',
    '43': 'Franche-Comt√©',
    '52': 'Pays de la Loire',
    '53': 'Bretagne',
    '54': 'Poitou-Charentes',
    '72': 'Aquitaine',
    '73': 'Midi-Pyr√©n√©es',
    '74': 'Limousin',
    '82': 'Rh√¥ne-Alpes',
    '83': 'Auvergne',
    '91': 'Languedoc-Roussillon',
    '93': 'Provence-Alpes-C√¥te d\'Azur',
    '94': 'Corse',
}

# Mapping anciennes ‚Üí nouvelles r√©gions
OLD_TO_NEW_REGION = {
    'Alsace': 'Grand Est',
    'Aquitaine': 'Nouvelle-Aquitaine',
    'Auvergne': 'Auvergne-Rh√¥ne-Alpes',
    'Basse-Normandie': 'Normandie',
    'Bourgogne': 'Bourgogne-Franche-Comt√©',
    'Bretagne': 'Bretagne',
    'Centre': 'Centre-Val de Loire',
    'Champagne-Ardenne': 'Grand Est',
    'Corse': 'Corse',
    'Franche-Comt√©': 'Bourgogne-Franche-Comt√©',
    'Haute-Normandie': 'Normandie',
    '√éle-de-France': '√éle-de-France',
    'Languedoc-Roussillon': 'Occitanie',
    'Limousin': 'Nouvelle-Aquitaine',
    'Lorraine': 'Grand Est',
    'Midi-Pyr√©n√©es': 'Occitanie',
    'Nord-Pas-de-Calais': 'Hauts-de-France',
    'Pays de la Loire': 'Pays de la Loire',
    'Picardie': 'Hauts-de-France',
    'Poitou-Charentes': 'Nouvelle-Aquitaine',
    'Provence-Alpes-C√¥te d\'Azur': 'Provence-Alpes-C√¥te d\'Azur',
    'Rh√¥ne-Alpes': 'Auvergne-Rh√¥ne-Alpes',
}


# ============================================================================
# PROCESSING IAS NATIONAL
# ============================================================================

def process_ias_national():
    """Traite les donn√©es IAS nationales (2018-2024)"""
    print("üìä 1/2 - PROCESSING IAS NATIONAL")
    print("-" * 70)

    filepath = RAW_DIR / 'Openhealth_S-Grippal.csv'

    if not filepath.exists():
        print(f"   ‚ùå Fichier non trouv√© : {filepath}")
        return None

    # Charger avec encoding latin-1 (caract√®res accentu√©s)
    df = pd.read_csv(filepath, sep=';', encoding='latin-1')

    print(f"   ‚Ä¢ Lignes charg√©es : {len(df)}")
    print(f"   ‚Ä¢ Colonnes : {df.columns.tolist()}")
    print(f"   ‚Ä¢ P√©riode : {df['PERIODE'].min()} ‚Üí {df['PERIODE'].max()}")

    # Nettoyer
    df['date'] = pd.to_datetime(df['PERIODE'])

    # Convertir IAS_liss√© (format fran√ßais avec virgule)
    df['ias_national'] = df['IAS_liss√©'].astype(str).str.replace(',', '.').astype(float)

    # Garder uniquement date et IAS
    df_clean = df[['date', 'ias_national']].copy()

    # Supprimer les valeurs manquantes
    df_clean = df_clean.dropna(subset=['ias_national'])

    print(f"   ‚Ä¢ Lignes apr√®s nettoyage : {len(df_clean)}")
    print(f"   ‚Ä¢ Stats IAS national :")
    print(f"     - Min  : {df_clean['ias_national'].min():.2f}")
    print(f"     - Max  : {df_clean['ias_national'].max():.2f}")
    print(f"     - Mean : {df_clean['ias_national'].mean():.2f}")

    # Sauvegarder
    output_path = PROCESSED_DIR / 'ias_national.csv'
    df_clean.to_csv(output_path, index=False)
    print(f"   ‚úÖ Sauvegard√© : {output_path}\n")

    return df_clean


# ============================================================================
# PROCESSING IAS R√âGIONAL
# ============================================================================

def process_ias_regional():
    """Traite les donn√©es IAS r√©gionales (nov 2023 - juil 2024)"""
    print("üìä 2/2 - PROCESSING IAS R√âGIONAL")
    print("-" * 70)

    filepath = RAW_DIR / 'Openhealth_S-Grippal_Regions.csv'

    if not filepath.exists():
        print(f"   ‚ùå Fichier non trouv√© : {filepath}")
        return None

    # Charger
    df = pd.read_csv(filepath, sep=';', encoding='latin-1')

    print(f"   ‚Ä¢ Lignes charg√©es : {len(df)}")
    print(f"   ‚Ä¢ P√©riode : {df['PERIODE'].min()} ‚Üí {df['PERIODE'].max()}")

    # Supprimer les lignes vides
    df = df[df['PERIODE'].notna() & (df['PERIODE'] != '')]

    # Parser la date (format dd-mm-yyyy)
    df['date'] = pd.to_datetime(df['PERIODE'], format='%d-%m-%Y', errors='coerce')
    df = df.dropna(subset=['date'])

    # Extraire les colonnes r√©gionales (Loc_Reg*)
    region_cols = [col for col in df.columns if col.startswith('Loc_Reg')]

    print(f"   ‚Ä¢ Colonnes r√©gionales trouv√©es : {len(region_cols)}")

    # Transformer en format long (une ligne par r√©gion par jour)
    dfs = []

    for col in region_cols:
        # Extraire le code r√©gion (ex: Loc_Reg42 ‚Üí 42)
        region_code = col.replace('Loc_Reg', '')

        if region_code not in REGION_CODE_TO_NAME:
            continue

        old_region_name = REGION_CODE_TO_NAME[region_code]
        new_region_name = OLD_TO_NEW_REGION.get(old_region_name, old_region_name)

        # Cr√©er un dataframe pour cette r√©gion
        df_region = df[['date', col]].copy()
        df_region.columns = ['date', 'ias_regional']
        df_region['region'] = new_region_name

        # Convertir IAS (format fran√ßais)
        df_region['ias_regional'] = (
            df_region['ias_regional']
            .astype(str)
            .str.replace(',', '.')
            .replace('NA', np.nan)
        )
        df_region['ias_regional'] = pd.to_numeric(df_region['ias_regional'], errors='coerce')

        # Supprimer les NA
        df_region = df_region.dropna(subset=['ias_regional'])

        dfs.append(df_region)

    # Concat√©ner toutes les r√©gions
    df_all = pd.concat(dfs, ignore_index=True)

    print(f"   ‚Ä¢ Lignes apr√®s transformation : {len(df_all)}")
    print(f"   ‚Ä¢ R√©gions uniques : {df_all['region'].nunique()}")
    print(f"   ‚Ä¢ R√©gions : {sorted(df_all['region'].unique())}")

    # Agr√©ger les anciennes r√©gions vers nouvelles (moyenne)
    df_grouped = df_all.groupby(['date', 'region']).agg({
        'ias_regional': 'mean'
    }).reset_index()

    print(f"   ‚Ä¢ Lignes apr√®s agr√©gation : {len(df_grouped)}")
    print(f"   ‚Ä¢ Stats IAS r√©gional :")
    print(f"     - Min  : {df_grouped['ias_regional'].min():.2f}")
    print(f"     - Max  : {df_grouped['ias_regional'].max():.2f}")
    print(f"     - Mean : {df_grouped['ias_regional'].mean():.2f}")

    # Sauvegarder
    output_path = PROCESSED_DIR / 'ias_regional.csv'
    df_grouped.to_csv(output_path, index=False)
    print(f"   ‚úÖ Sauvegard√© : {output_path}\n")

    return df_grouped


# ============================================================================
# MAIN
# ============================================================================

def main():
    # Processing
    df_national = process_ias_national()
    df_regional = process_ias_regional()

    # R√©sum√©
    print("="*70)
    print("‚úÖ PROCESSING TERMIN√â")
    print("="*70)

    if df_national is not None:
        print(f"\nüìä IAS National :")
        print(f"   ‚Ä¢ {len(df_national)} jours")
        print(f"   ‚Ä¢ {df_national['date'].min()} ‚Üí {df_national['date'].max()}")

    if df_regional is not None:
        print(f"\nüìä IAS R√©gional :")
        print(f"   ‚Ä¢ {len(df_regional)} lignes (r√©gion √ó jour)")
        print(f"   ‚Ä¢ {df_regional['date'].min()} ‚Üí {df_regional['date'].max()}")
        print(f"   ‚Ä¢ {df_regional['region'].nunique()} r√©gions")

    print(f"\nüìÅ Fichiers g√©n√©r√©s dans : {PROCESSED_DIR}/")
    print("   ‚Ä¢ ias_national.csv")
    print("   ‚Ä¢ ias_regional.csv")

    print("\nüéØ Prochaine √©tape : docker-compose exec streamlit python scripts/merge_data.py")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
