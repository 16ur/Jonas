#!/usr/bin/env python3
"""
Script de merge des 3 fichiers de donn√©es √©pid√©miologiques
Cr√©e un dataframe unifi√© au niveau R√âGION √ó SEMAINE pour le ML et la visualisation
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')


# ============================================================================
# MAPPINGS G√âOGRAPHIQUES
# ============================================================================

# Mapping d√©partement ‚Üí r√©gion (nouvelles r√©gions depuis 2016)
DEPT_TO_REGION = {
    '01': 'Auvergne-Rh√¥ne-Alpes', '03': 'Auvergne-Rh√¥ne-Alpes', '07': 'Auvergne-Rh√¥ne-Alpes',
    '15': 'Auvergne-Rh√¥ne-Alpes', '26': 'Auvergne-Rh√¥ne-Alpes', '38': 'Auvergne-Rh√¥ne-Alpes',
    '42': 'Auvergne-Rh√¥ne-Alpes', '43': 'Auvergne-Rh√¥ne-Alpes', '63': 'Auvergne-Rh√¥ne-Alpes',
    '69': 'Auvergne-Rh√¥ne-Alpes', '73': 'Auvergne-Rh√¥ne-Alpes', '74': 'Auvergne-Rh√¥ne-Alpes',

    '21': 'Bourgogne-Franche-Comt√©', '25': 'Bourgogne-Franche-Comt√©', '39': 'Bourgogne-Franche-Comt√©',
    '58': 'Bourgogne-Franche-Comt√©', '70': 'Bourgogne-Franche-Comt√©', '71': 'Bourgogne-Franche-Comt√©',
    '89': 'Bourgogne-Franche-Comt√©', '90': 'Bourgogne-Franche-Comt√©',

    '22': 'Bretagne', '29': 'Bretagne', '35': 'Bretagne', '56': 'Bretagne',

    '18': 'Centre-Val de Loire', '28': 'Centre-Val de Loire', '36': 'Centre-Val de Loire',
    '37': 'Centre-Val de Loire', '41': 'Centre-Val de Loire', '45': 'Centre-Val de Loire',

    '2A': 'Corse', '2B': 'Corse',

    '08': 'Grand Est', '10': 'Grand Est', '51': 'Grand Est', '52': 'Grand Est',
    '54': 'Grand Est', '55': 'Grand Est', '57': 'Grand Est', '67': 'Grand Est',
    '68': 'Grand Est', '88': 'Grand Est',

    '02': 'Hauts-de-France', '59': 'Hauts-de-France', '60': 'Hauts-de-France',
    '62': 'Hauts-de-France', '80': 'Hauts-de-France',

    '75': '√éle-de-France', '77': '√éle-de-France', '78': '√éle-de-France',
    '91': '√éle-de-France', '92': '√éle-de-France', '93': '√éle-de-France',
    '94': '√éle-de-France', '95': '√éle-de-France',

    '14': 'Normandie', '27': 'Normandie', '50': 'Normandie', '61': 'Normandie', '76': 'Normandie',

    '16': 'Nouvelle-Aquitaine', '17': 'Nouvelle-Aquitaine', '19': 'Nouvelle-Aquitaine',
    '23': 'Nouvelle-Aquitaine', '24': 'Nouvelle-Aquitaine', '33': 'Nouvelle-Aquitaine',
    '40': 'Nouvelle-Aquitaine', '47': 'Nouvelle-Aquitaine', '64': 'Nouvelle-Aquitaine',
    '79': 'Nouvelle-Aquitaine', '86': 'Nouvelle-Aquitaine', '87': 'Nouvelle-Aquitaine',

    '09': 'Occitanie', '11': 'Occitanie', '12': 'Occitanie', '30': 'Occitanie',
    '31': 'Occitanie', '32': 'Occitanie', '34': 'Occitanie', '46': 'Occitanie',
    '48': 'Occitanie', '65': 'Occitanie', '66': 'Occitanie', '81': 'Occitanie', '82': 'Occitanie',

    '44': 'Pays de la Loire', '49': 'Pays de la Loire', '53': 'Pays de la Loire',
    '72': 'Pays de la Loire', '85': 'Pays de la Loire',

    '04': 'Provence-Alpes-C√¥te d\'Azur', '05': 'Provence-Alpes-C√¥te d\'Azur',
    '06': 'Provence-Alpes-C√¥te d\'Azur', '13': 'Provence-Alpes-C√¥te d\'Azur',
    '83': 'Provence-Alpes-C√¥te d\'Azur', '84': 'Provence-Alpes-C√¥te d\'Azur',

    # DOM-TOM
    '971': 'Guadeloupe', '972': 'Martinique', '973': 'Guyane',
    '974': 'R√©union', '976': 'Mayotte'
}

# Mapping anciennes r√©gions (IAS) ‚Üí nouvelles r√©gions (standardis√©es)
OLD_TO_NEW_REGION = {
    'Alsace': 'Grand Est',
    'Aquitaine': 'Nouvelle-Aquitaine',
    'Auvergne': 'Auvergne-Rh√¥ne-Alpes',
    'Basse-Normandie': 'Normandie',
    'Bourgogne': 'Bourgogne-Franche-Comt√©',
    'Bretagne': 'Bretagne',
    'Centre': 'Centre-Val de Loire',
    'Champagne-Ardenne': 'Grand Est',
    'Corse': 'Corse',
    'Franche-Comt√©': 'Bourgogne-Franche-Comt√©',
    'Haute-Normandie': 'Normandie',
    '√éle-de-France': '√éle-de-France',
    'Languedoc-Roussillon': 'Occitanie',
    'Limousin': 'Nouvelle-Aquitaine',
    'Lorraine': 'Grand Est',
    'Midi-Pyr√©n√©es': 'Occitanie',
    'Nord-Pas-de-Calais': 'Hauts-de-France',
    'Pays de la Loire': 'Pays de la Loire',
    'Picardie': 'Hauts-de-France',
    'Poitou-Charentes': 'Nouvelle-Aquitaine',
    'Provence-Alpes-C√¥te d\'Azur': 'Provence-Alpes-C√¥te d\'Azur',
    'Rh√¥ne-Alpes': 'Auvergne-Rh√¥ne-Alpes',
}

# Standardisation des noms de r√©gions dans urgences_clean
URGENCES_REGION_MAPPING = {
    'Auvergne et Rh√¥ne-Alpes': 'Auvergne-Rh√¥ne-Alpes',
    'Bourgogne et Franche-Comt√©': 'Bourgogne-Franche-Comt√©',
    'Nouvelle Aquitaine': 'Nouvelle-Aquitaine',
}


# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

def get_week_start(date):
    """Retourne le lundi de la semaine pour une date donn√©e"""
    if pd.isna(date):
        return pd.NaT
    return date - timedelta(days=date.weekday())


def add_temporal_features(df, date_col='date_semaine'):
    """Ajoute des features temporelles au dataframe"""
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col])

    df['annee'] = df[date_col].dt.year
    df['mois'] = df[date_col].dt.month
    df['semaine_annee'] = df[date_col].dt.isocalendar().week
    df['jour_annee'] = df[date_col].dt.dayofyear

    # Saison √©pid√©miologique (octobre-mars = hiver, avril-sept = √©t√©)
    df['saison'] = df['mois'].apply(lambda m: 'hiver' if m in [10, 11, 12, 1, 2, 3] else 'ete')

    # Ann√©e √©pid√©miologique (commence en octobre)
    df['annee_epidemio'] = df.apply(
        lambda row: row['annee'] if row['mois'] < 10 else row['annee'] + 1,
        axis=1
    )

    return df


# ============================================================================
# CHARGEMENT ET PREPROCESSING
# ============================================================================

def load_and_process_grippe():
    """Charge et traite les donn√©es de vaccination grippe"""
    print("üìä Chargement des donn√©es de vaccination grippe...")

    df = pd.read_csv('data/processed/grippe_departement.csv')

    # Renommer les colonnes
    df.columns = ['annee', 'dept_code', 'dept_name', 'vacc_moins_65_risque',
                  'vacc_65_plus', 'vacc_65_74', 'vacc_75_plus']

    # Mapper vers les nouvelles r√©gions
    df['region'] = df['dept_code'].astype(str).map(DEPT_TO_REGION)

    # Supprimer les d√©partements sans mapping (DOM-TOM non pr√©sents dans urgences)
    df = df.dropna(subset=['region'])

    # Agr√©ger par r√©gion et ann√©e (moyenne des taux de vaccination)
    df_agg = df.groupby(['annee', 'region']).agg({
        'vacc_moins_65_risque': 'mean',
        'vacc_65_plus': 'mean',
        'vacc_65_74': 'mean',
        'vacc_75_plus': 'mean'
    }).reset_index()

    print(f"   ‚úì {len(df_agg)} lignes (r√©gion √ó ann√©e)")
    return df_agg


def load_and_process_ias():
    """
    Charge et traite les donn√©es IAS (Indicateur Activit√© Syndromique)
    Strat√©gie hybride : IAS national (2018-2024) + IAS r√©gional (2023-2024)
    """
    print("üìä Chargement des donn√©es IAS (strat√©gie hybride)...")

    # ========== 1. IAS NATIONAL (2018-2024) ==========
    print("   ‚Ä¢ IAS national (2018-2024)...")
    df_national = pd.read_csv('data/processed/ias_national.csv')
    df_national['date'] = pd.to_datetime(df_national['date'])
    df_national['date_semaine'] = df_national['date'].apply(get_week_start)

    # Agr√©ger par semaine (moyenne hebdomadaire)
    df_national_week = df_national.groupby('date_semaine').agg({
        'ias_national': 'mean'
    }).reset_index()

    print(f"     ‚úì {len(df_national_week)} semaines")

    # ========== 2. IAS R√âGIONAL (2023-2024) ==========
    print("   ‚Ä¢ IAS r√©gional (2023-2024)...")
    df_regional = pd.read_csv('data/processed/ias_regional.csv')
    df_regional['date'] = pd.to_datetime(df_regional['date'])
    df_regional['date_semaine'] = df_regional['date'].apply(get_week_start)

    # Agr√©ger par semaine et r√©gion
    df_regional_week = df_regional.groupby(['date_semaine', 'region']).agg({
        'ias_regional': ['mean', 'std', 'min', 'max']
    }).reset_index()

    # Flatten columns
    df_regional_week.columns = ['date_semaine', 'region', 'taux_ias_moyen', 'taux_ias_std',
                                 'taux_ias_min', 'taux_ias_max']

    print(f"     ‚úì {len(df_regional_week)} lignes (r√©gion √ó semaine)")
    print(f"     ‚úì {df_regional_week['region'].nunique()} r√©gions")

    # ========== 3. COMBINER : National comme base, R√©gional en override ==========
    # On retourne les deux dataframes pour le merge
    return df_national_week, df_regional_week


def load_and_process_urgences():
    """Charge et traite les donn√©es urgences et SOS m√©decins"""
    print("üìä Chargement des donn√©es urgences...")

    df = pd.read_csv('data/processed/urgences_clean.csv')
    df['date'] = pd.to_datetime(df['date'])

    # Standardiser les noms de r√©gions
    df['region'] = df['region'].replace(URGENCES_REGION_MAPPING)

    # Les donn√©es sont d√©j√† hebdomadaires, on calcule juste le lundi de la semaine
    df['date_semaine'] = df['date'].apply(get_week_start)

    # Renommer pour clart√©
    df = df.rename(columns={
        'urgences': 'urgences_grippe',
        'sos': 'sos_medecins'
    })

    df = df[['date_semaine', 'region', 'urgences_grippe', 'sos_medecins']]

    print(f"   ‚úì {len(df)} lignes (r√©gion √ó semaine)")
    return df


# ============================================================================
# MERGE PRINCIPAL
# ============================================================================

def merge_all_data():
    """Merge les 3 sources de donn√©es en un dataframe unifi√© avec strat√©gie hybride IAS"""
    print("\nüîó MERGE DES DONN√âES\n" + "="*60)

    # Chargement
    df_grippe = load_and_process_grippe()
    df_ias_national, df_ias_regional = load_and_process_ias()
    df_urgences = load_and_process_urgences()

    print("\nüîÄ Fusion des datasets...")

    # ========== STRAT√âGIE HYBRIDE IAS ==========
    # 1. Merge urgences avec IAS national (toutes r√©gions re√ßoivent la m√™me valeur)
    print("   ‚Ä¢ √âtape 1/3 : Urgences + IAS national...")
    df = pd.merge(
        df_urgences,
        df_ias_national,
        on='date_semaine',
        how='left'
    )
    print(f"     ‚úì {len(df)} lignes")

    # 2. Merge avec IAS r√©gional (override quand disponible)
    print("   ‚Ä¢ √âtape 2/3 : Ajout IAS r√©gional (override)...")
    df = pd.merge(
        df,
        df_ias_regional,
        on=['date_semaine', 'region'],
        how='left'
    )

    # 3. Cr√©er colonne IAS hybride : r√©gional si dispo, sinon national
    df['taux_ias'] = df['taux_ias_moyen'].fillna(df['ias_national'])

    # Garder les stats r√©gionales quand disponibles
    df['taux_ias_std'] = df['taux_ias_std'].fillna(0)
    df['taux_ias_min'] = df['taux_ias_min'].fillna(df['taux_ias'])
    df['taux_ias_max'] = df['taux_ias_max'].fillna(df['taux_ias'])

    # Supprimer colonnes temporaires
    df = df.drop(columns=['ias_national', 'taux_ias_moyen'])

    print(f"     ‚úì IAS hybride cr√©√© (r√©gional prioritaire)")

    # Ajouter l'ann√©e pour le merge avec grippe
    df['annee'] = pd.to_datetime(df['date_semaine']).dt.year

    # 4. Merge avec vaccination grippe
    print("   ‚Ä¢ √âtape 3/3 : Ajout vaccination...")
    df = pd.merge(
        df,
        df_grippe,
        on=['annee', 'region'],
        how='left'
    )

    print(f"   ‚úì Total final : {len(df)} lignes")

    # R√©ordonner les colonnes
    cols_order = [
        'date_semaine', 'region', 'annee',
        'taux_ias', 'taux_ias_std', 'taux_ias_min', 'taux_ias_max',
        'urgences_grippe', 'sos_medecins',
        'vacc_moins_65_risque', 'vacc_65_plus', 'vacc_65_74', 'vacc_75_plus'
    ]
    df = df[cols_order]

    # Trier par date et r√©gion
    df = df.sort_values(['date_semaine', 'region']).reset_index(drop=True)

    return df


def add_features_and_clean(df):
    """Ajoute des features et nettoie le dataframe final"""
    print("\nüé® FEATURE ENGINEERING\n" + "="*60)

    # Features temporelles
    df = add_temporal_features(df, 'date_semaine')

    # Forward fill pour la vaccination (annuelle ‚Üí hebdo)
    vacc_cols = ['vacc_moins_65_risque', 'vacc_65_plus', 'vacc_65_74', 'vacc_75_plus']
    df[vacc_cols] = df.groupby('region')[vacc_cols].ffill()

    print(f"   ‚úì Features temporelles ajout√©es (saison, semaine_annee, etc.)")

    # Statistiques de qualit√©
    print(f"\nüìà STATISTIQUES FINALES\n" + "="*60)
    print(f"   ‚Ä¢ P√©riode : {df['date_semaine'].min()} ‚Üí {df['date_semaine'].max()}")
    print(f"   ‚Ä¢ R√©gions : {df['region'].nunique()} r√©gions")
    print(f"   ‚Ä¢ Total lignes : {len(df)}")
    print(f"\n   ‚Ä¢ Valeurs manquantes :")
    missing = df.isnull().sum()
    missing = missing[missing > 0].sort_values(ascending=False)
    for col, count in missing.items():
        pct = 100 * count / len(df)
        print(f"     - {col}: {count} ({pct:.1f}%)")

    return df


# ============================================================================
# MAIN
# ============================================================================

def main():
    print("\n" + "="*60)
    print("  MERGE DONN√âES √âPID√âMIOLOGIQUES - HACKATHON")
    print("="*60 + "\n")

    # Merge
    df = merge_all_data()

    # Features
    df = add_features_and_clean(df)

    # Sauvegarde
    output_path = 'data/processed/master_dataframe.csv'
    df.to_csv(output_path, index=False)

    print(f"\n‚úÖ Fichier sauvegard√© : {output_path}")
    print(f"   üì¶ Shape : {df.shape}")
    print(f"\n{'='*60}\n")

    # Aper√ßu
    print("üìã APER√áU DES DONN√âES (5 premi√®res lignes) :\n")
    print(df.head().to_string())

    return df


if __name__ == "__main__":
    df = main()
